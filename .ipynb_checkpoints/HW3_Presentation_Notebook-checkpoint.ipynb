{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb50142",
   "metadata": {},
   "source": [
    "<h2><center>ECE 594N: Homework 4 Group Project</center></h2>\n",
    "<h1><center>Human Pose Classifcation Using Manifold Learning</center></h1>\n",
    "<h3><center>by Abhijith Atreya, Jax Burd, and Christos Zangos</center></h3>\n",
    "    \n",
    "---------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97fd6b3",
   "metadata": {},
   "source": [
    "# Project Goal\n",
    "\n",
    "To distinguish between certain actions using 2D full body-based keypoints pulled from an open dataset. We first performed 2 PCA methods to extract a minimum number of components to represent our data. \n",
    "\n",
    "![](images/human_poses.JPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f6e62",
   "metadata": {},
   "source": [
    "# MPII Human Pose Dataset\n",
    "- <b>Dataset available at:</b> <http://human-pose.mpi-inf.mpg.de/>\n",
    "\n",
    "\n",
    "- <b>Citation:</b> <em>Mykhaylo Andriluka and Leonid Pishchulin and Peter Gehler and Schiele, Bernt. 2D Human Pose Estimation: New Benchmark and State of the Art Analysis. IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Jun 2014</em>\n",
    "\n",
    "Created as a new benchmark for 2D human pose estimation in 2014, MPII Human pose features about 25K images total, and over 40K people with annotated body joints. The images and their annotations depict 410 different human activities. Some examples are (but not limited to) dancing, running, playing a musical intrument, meditating, etc.\n",
    "\n",
    "![](images/human_pose_activities.PNG)\n",
    "\n",
    "All images were extracted from YouTube, and was the result of a collaboration from researches at the Max Planck Institute for Intelligent Systems in Germany and Stanford University in the United States.\n",
    "\n",
    "### Keypoint Labels\n",
    "The dataset annotated all of joints on their images with the 16 total features listed below, each containing a x and y position coordinate.\n",
    "\n",
    "| Legs \t| ID \t| Head + Torso \t| ID \t| Arms \t| ID \t|\n",
    "|:---:\t|:---:\t|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "| right ankle \t| 0 \t| pelvis \t| 6 \t| right wrist \t| 10 \t|\n",
    "| right knee \t| 1 \t| thorax \t| 7 \t| right elbow \t| 11 \t|\n",
    "| right hip \t| 2 \t| neck \t| 8 \t| right shoulder \t| 12 \t|\n",
    "| left hip \t| 3 \t| head \t| 9 \t| left shoulder \t| 13 \t|\n",
    "| left knee \t| 4 \t|  \t|  \t| left elbow \t| 14 \t|\n",
    "| left ankle \t| 5 \t|  \t|  \t| left wrist \t| 15 \t|\n",
    "\n",
    "<h2><center>Insert Keypoint Skeleton Here</center></h2>\n",
    "\n",
    "\n",
    "### Running and Cycling\n",
    "In our project we wanted to focus on two activities within the dataset that would be reasonable to distinguish based off their keypoint skeletons. For this reason we decided to attempt classifying between the activities of <b>running</b> and <b>cycling</b>, as it was assumed their poses are distinct enough to yeild good results.\n",
    "\n",
    "![](images/keypoints.JPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f966a65",
   "metadata": {},
   "source": [
    "# Principle Component Analysis\n",
    "\n",
    "\n",
    "## On Euclidean Space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c86235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection of First X Pricinple Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd81416",
   "metadata": {},
   "source": [
    "## On Kendall Shape Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tangent PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection of First X Pricinple Tangent Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5028df",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## On Euclidean Space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fe4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe18a59",
   "metadata": {},
   "source": [
    "## On Tangent Space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8908ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28d14c4",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3660841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Principle Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c899274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Principle Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Principle Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f6c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 Principle Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 36 Components (All)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282410fc",
   "metadata": {},
   "source": [
    "# Conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f9ca61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
